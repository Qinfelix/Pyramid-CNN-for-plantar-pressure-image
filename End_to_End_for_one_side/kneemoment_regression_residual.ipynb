{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "# 数据预处理相关函数\n",
    "from Reader import Footscan_reader\n",
    "from Reader import gait_data_reader\n",
    "from Convlstm import ConvLSTM\n",
    "import random\n",
    "LEARING_RATE=0.001\n",
    "BATCH_SIZE=512\n",
    "INPUT_FEATURES=5\n",
    "HIDDEN_FEATURES_LIST=[64,128]\n",
    "KERNEL_SIZE_LIST=[(1,1),(2,2),(3,3),(4,4),(3,3)]\n",
    "EPOCH_NUM=200\n",
    "DEVICE=torch.device('cuda')\n",
    "TIME_STEP=202\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 首先先读数据，并作配准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终完成填充与拼接,最终得到的input data的维度为 torch.Size([162, 202, 1, 50, 35])\n",
      "下面把这次回访的同一趟的步态数据和足压数据匹配录入\n",
      "录入完毕，这一次回访一共有 162 组数据是可作为有效数据的\n",
      "\n",
      "\n",
      "开始寻找  王晓军  在  12  week康复周次的足压数据,具体的task为walk,分组是vicon\n"
     ]
    }
   ],
   "source": [
    "'''之前的是对每一个gaitdata，找对应的name和week的所有趟的数据，然后选出对应的那一趟，\n",
    "这样就导致每一个时间点的十趟数据被检索了十次，过于浪费时间，可以修改一下:\n",
    "修改成，我先对有gait数据的name和week的组合做一个统计，然后对这个组合所有趟的足压数据都进行检索，\n",
    "如果检索到了，再根据检索到的每一趟，反过来看这一趟有没有gait数据，然后做匹配录入'''\n",
    "\n",
    "def get_name_week_list(gait_data_list):\n",
    "    name_week_list=[]\n",
    "    name_list=[]\n",
    "    for gaitdata in gait_data_list:\n",
    "        name_week=(info_dic.get(gaitdata.name),str(gaitdata.week*12))\n",
    "        if name_week[0] in name_list:\n",
    "            pass\n",
    "        else:\n",
    "            name_list.append(name_week[0])\n",
    "        if name_week in name_week_list:\n",
    "            pass\n",
    "        else:\n",
    "            name_week_list.append(name_week)\n",
    "    print('该部分数据中共有 {} 位患者，平均每位患者有{}次回访，共计{}次,平均每次回访测试了{}组数据，共计{}组'.format(len(name_list),len(name_week_list)/len(name_list),len(name_week_list),len(gait_data_list)/len(name_week_list),len(gait_data_list)))\n",
    "    print('\\n \\n')\n",
    "    return name_week_list\n",
    "\n",
    "\n",
    "info_dic={}\n",
    "info=pd.read_excel('G:\\\\qinyue\\\\data\\\\DJO\\\\info.xlsx')\n",
    "for i in range(len(info)):\n",
    "    info_dic[info.loc[i,'编号']]=info.loc[i,'姓名']\n",
    "\n",
    "\n",
    "footscan_reader = Footscan_reader()\n",
    "gaitdata_reader=gait_data_reader()\n",
    "gait_data_list=gaitdata_reader.get_data(gait_data_category='kneemoment')\n",
    "valid_input=[]\n",
    "valid_gaitdata=[]\n",
    "valid_week=[]\n",
    "valid_delta=[]\n",
    "\n",
    "\n",
    "for name_week in get_name_week_list(gait_data_list):\n",
    "    #寻找这次回访的所有趟的足压数据\n",
    "    #此时的week就是这组数据隶属的task——-12，-24，-36，-48，12，24，36，48——患侧为左脚是负，患侧为右脚是正\n",
    "    data,week,count,delta=footscan_reader.get_data('walk','vicon',name_week[0],name_week[1],augment=1)\n",
    "    if type(data)!=int:\n",
    "        print('下面把这次回访的同一趟的步态数据和足压数据匹配录入')\n",
    "        num=0\n",
    "        for i in range(len(count)):\n",
    "            for gaitdata in gait_data_list:\n",
    "                if info_dic.get(gaitdata.name)==name_week[0] and str(gaitdata.week*12)==name_week[1] and gaitdata.count==count[i]:\n",
    "                    pressure_aver=torch.mean(data[i])\n",
    "                    if pressure_aver==0:\n",
    "                        print('该次回访第{}count的足压数据均为0, 为无效数据，不给记录'.format(count[i]))\n",
    "                    else:\n",
    "                        valid_input.append(data[i])\n",
    "                        valid_week.append(int(week[i]))\n",
    "                        valid_delta.append(delta[i])\n",
    "                        valid_gaitdata.append(gaitdata)\n",
    "                        num+=1\n",
    "                    # #如果确保只有一个每一趟只有一个gaitdata文件，那么就可以break来减少时间\n",
    "                    # break\n",
    "        print('录入完毕，这一次回访一共有 {} 组数据是可作为有效数据的'.format(num))\n",
    "        print('\\n')\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(valid_gaitdata),len(valid_input),len(valid_week),len(valid_delta))\n",
    "print(valid_gaitdata[0].data.shape)\n",
    "print(valid_delta[0])\n",
    "print(pd.value_counts(valid_week))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把输入处理为每一帧的数据组成的batch，把输出处理为norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先对足压片段和膝关节力矩曲线捆绑打乱,同时把患侧为左和患侧为右的数据分开，分为两组\n",
    "\n",
    "origin_list=[]\n",
    "\n",
    "for i in range(len(valid_gaitdata)):\n",
    "    origin_list.append((valid_input[i],valid_gaitdata[i],valid_delta[i],valid_week[i]))\n",
    "random.shuffle(origin_list)\n",
    "\n",
    "random_gaitdata_lacld=[]\n",
    "random_input_lacld=[]\n",
    "random_delta_lacld=[]\n",
    "random_gaitdata_racld=[]\n",
    "random_input_racld=[]\n",
    "random_delta_racld=[]\n",
    "\n",
    "\n",
    "for i in range(len(origin_list)):\n",
    "    if(origin_list[i][3]<0):#代表患侧是左边\n",
    "        random_input_lacld.append(origin_list[i][0])\n",
    "        random_gaitdata_lacld.append(origin_list[i][1])\n",
    "        random_delta_lacld.append(origin_list[i][2])\n",
    "    else:\n",
    "        random_input_racld.append(origin_list[i][0])\n",
    "        random_gaitdata_racld.append(origin_list[i][1])\n",
    "        random_delta_racld.append(origin_list[i][2])\n",
    "\n",
    "\n",
    "print(len(random_input_lacld),len(random_input_racld))\n",
    "\n",
    "#决定训练的task是lacld还是racld\n",
    "\n",
    "this_input=random_input_lacld\n",
    "this_gaitdata=random_gaitdata_lacld\n",
    "this_delta=random_delta_lacld\n",
    "# this_input=random_input_racld\n",
    "# this_gaitdata=random_gaitdata_racld\n",
    "# this_delta=random_delta_racld\n",
    "whichfoot='R'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意目前我们训练的task是：某一确定患侧的患者的某一个确定的脚侧片段与对应腿测膝关节力矩之间的关系\n",
    "\n",
    "比如lacld的 L 脚与 L 腿膝关节力矩之间的关系 ---- 1st\n",
    "\n",
    "racld的 L 脚与 L 腿膝关节力矩之间的关系 ---- 2nd\n",
    "\n",
    "racld的 R 和 R --- 3rd\n",
    "\n",
    "lacld 的 R-R --- 4th\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理label\n",
    "\n",
    "label_list=[]\n",
    "for i in range(len(this_gaitdata)):\n",
    "    gaitdata=this_gaitdata[i].data\n",
    "    if whichfoot=='L':\n",
    "        print('此次预测的输入与输出是左脚足压-左腿膝关节力矩')\n",
    "        for j in range(101):\n",
    "            label_list.append(torch.norm(gaitdata[j,:]))\n",
    "    else:\n",
    "        print('此次预测的输入与输出是右脚足压-右腿膝关节力矩')\n",
    "        for j in range(101,202):\n",
    "            label_list.append(torch.norm(gaitdata[j,:]))\n",
    "LABEL=torch.stack(label_list)\n",
    "LABEL=LABEL.unsqueeze(-1)\n",
    "#对label放大10倍，这样就避免了doubel和float的精度问题\n",
    "LABEL=LABEL*10\n",
    "print(LABEL.shape)\n",
    "print(torch.mean(LABEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理input——每一帧的通道扩充到5——this frame, last frame, dif_before,next_frame,dif_next\n",
    "#同时要先把dif这个数据扩大10倍，使其与这一帧的数据同一个数量级，然后再把DATA的数字统一都都扩大100倍，使得和膝关节力矩一个数量级\n",
    "\n",
    "input_list=[]\n",
    "for i in range(len(this_input)):\n",
    "    pressure_video=this_input[i]\n",
    "    last_pressure=torch.zeros((50,35))\n",
    "    index_list=[]\n",
    "    #先判断task的脚测是L还是R\n",
    "    if whichfoot=='L':\n",
    "        index_list=range(101)\n",
    "    else:\n",
    "        index_list=range(101,202)\n",
    "    \n",
    "    for j in index_list:\n",
    "        this_pressure=pressure_video[j,0,:,:]\n",
    "        if j==100 or 201:\n",
    "            next_pressure=torch.zeros((50,35))\n",
    "        else:\n",
    "            next_pressure=pressure_video[j+1,0,:,:]\n",
    "        #考虑进入时间因素（用delta来表示）\n",
    "        dif_former=(this_pressure-last_pressure)/ this_delta[i][0] *10\n",
    "        dif_latter=(next_pressure-this_pressure)/this_delta[i][0] *10\n",
    "        # print(torch.mean(this_pressure),torch.mean(dif_pressure))\n",
    "        input_list.append(torch.stack([this_pressure,last_pressure,next_pressure,dif_former,dif_latter]))\n",
    "        last_pressure=this_pressure\n",
    "DATA=torch.stack(input_list)\n",
    "DATA=DATA*100\n",
    "print(DATA.shape)\n",
    "print(torch.mean(DATA))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "从数据中分离出测试集\n",
    "'''\n",
    "test_begin_index=DATA.shape[0]-DATA.shape[0]//10\n",
    "#测试集取最后的5000帧（50组）\n",
    "TRAIN_X=DATA[0:test_begin_index]\n",
    "TRAIN_Y=LABEL[0:test_begin_index]\n",
    "TEST_X=DATA[test_begin_index:-1]\n",
    "TEST_Y=LABEL[test_begin_index:-1]\n",
    "\n",
    "\n",
    "print('训练集输入和标签的大小分别为{},{};测试集输入和标签的大小分别为{},{}'.format(TRAIN_X.shape,TRAIN_Y.shape,TEST_X.shape,TEST_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(TEST_X.shape[0]):\n",
    "    print('第{}个数据的输入第一通道均值为{},第二通道均值为{},要预测的label均值为{}'.format(i,torch.mean(TEST_X[i]),torch.mean(TEST_X[i]-TEST_X[max(i-1,0)]),TEST_Y[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#回归模型构建\n",
    "'''\n",
    "2023/4/22\n",
    "处理足压片段来预测步态周期的力矩曲线\n",
    "\n",
    "模型概况：\n",
    "    金字塔conv:总共有四个copy——分别是三个conv和一个residual(shortcut-conv为(1,1))\n",
    "    Maxpooling:\n",
    "    BN:\n",
    "    conv2:\n",
    "    maxpooling:\n",
    "    flatten:\n",
    "    linear*3(12288-100-32-1)\n",
    "\n",
    "输入输出：\n",
    "    输入：该时刻的足压图像+该帧的变化量(batch,channel=5,height=50,width=35)\n",
    "    输出：该时刻的膝关节力矩(batch)\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,batch_size,input_features,hidden_features_list,kernel_size_list):\n",
    "        super(Net,self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.input_features = input_features\n",
    "        self.hidden_features_list=hidden_features_list\n",
    "        self.kernel_size_list=kernel_size_list\n",
    "\n",
    "        self.BN1=nn.BatchNorm2d(input_features).to(DEVICE)\n",
    "        self.pymarid_conv_1=nn.Conv2d(input_features,hidden_features_list[0],kernel_size_list[0],padding='same').to(DEVICE)                              \n",
    "        self.pymarid_conv_2=nn.Conv2d(input_features,hidden_features_list[0],kernel_size_list[1],padding='same').to(DEVICE)\n",
    "        self.pymarid_conv_3=nn.Conv2d(input_features,hidden_features_list[0],kernel_size_list[2],padding='same').to(DEVICE)\n",
    "        self.pymarid_conv_4=nn.Conv2d(input_features,hidden_features_list[0],kernel_size_list[3],padding='same').to(DEVICE)\n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(hidden_features_list[0]*4),\n",
    "            nn.Conv2d(hidden_features_list[0]*4,hidden_features_list[1],kernel_size_list[4],padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.Linear=nn.Sequential(\n",
    "            nn.Linear(hidden_features_list[1]*12*8,100),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(100,32),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(32,1),\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def forward(self,x):\n",
    "        if x.ndim!=4:\n",
    "            raise ValueError('输入数据ndim不为4')\n",
    "        else:\n",
    "            batch,features,height,width= x.shape\n",
    "            if batch!=self.batch_size or features != self.input_features:\n",
    "                raise ValueError('输入数据batch size 或者 input features 与model不符')\n",
    "            else:\n",
    "                pyramid_conv_output_list=[self.pymarid_conv_1(x),self.pymarid_conv_2(x),self.pymarid_conv_3(x),self.pymarid_conv_4(x)]\n",
    "                pyramid_conv_output=torch.cat(pyramid_conv_output_list,dim=1)\n",
    "                conv2_output=self.conv2(pyramid_conv_output)\n",
    "                y=self.Linear(conv2_output.reshape(batch,-1))\n",
    "                return y\n",
    "\n",
    "model = Net(BATCH_SIZE,INPUT_FEATURES,HIDDEN_FEATURES_LIST,KERNEL_SIZE_LIST).to(DEVICE)     \n",
    "print(model)\n",
    "a = torch.ones((BATCH_SIZE,INPUT_FEATURES,50,35)).to(DEVICE)\n",
    "b = model(a)\n",
    "print(b.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "def timesince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "CRITERION = nn.MSELoss()\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters(), lr=LEARING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRE(pred,train_y):\n",
    "    #输入时两个(batchsize,1)的二维tensor\n",
    "    relative_error=abs(pred-train_y)/train_y\n",
    "    return torch.mean(relative_error)\n",
    "\n",
    "\n",
    "def train(train_x,train_y,test_x,test_y,batch_size,epoch_num,criterion,optimizer):\n",
    "    train_loss=[]\n",
    "    test_loss=[]\n",
    "    train_MRE=[]\n",
    "    test_MRE=[]\n",
    "    train_NRMSE=[]\n",
    "    test_NRMSE=[]\n",
    "    full_batch = train_y.shape[0]\n",
    "    batch_num=full_batch//batch_size\n",
    "    train_x_list = torch.split(train_x,batch_size,dim=0)\n",
    "    train_y_list = torch.split(train_y,batch_size,dim=0)\n",
    "    early_stop_p = 0\n",
    "    for i in range(epoch_num):\n",
    "        #每一个epoch是对整个batch的训练\n",
    "        loss_each_batch=[]\n",
    "        MRE_each_batch=[]\n",
    "        NRMSE_each_batch=[]\n",
    "        for j in range(batch_num):\n",
    "            train_x=train_x_list[j].to(DEVICE)\n",
    "            train_y=train_y_list[j].to(DEVICE)\n",
    "            output=model(train_x).to(DEVICE)\n",
    "            output=output.float()\n",
    "            train_y=train_y.float()\n",
    "            loss = criterion(output,train_y)\n",
    "            loss_each_batch.append(loss.data.cpu())\n",
    "            optimizer.zero_grad()   \n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "\n",
    "            MRE_each_batch.append(MRE(output,train_y).data.cpu())\n",
    "            NRMSE_each_batch.append(np.sqrt(loss.data.cpu())/(torch.max(train_y)-torch.min(train_y)).data.cpu())\n",
    "\n",
    "        NRMSE_this_epoch=np.average(NRMSE_each_batch)\n",
    "        loss_this_epoch=np.average(loss_each_batch)\n",
    "        MRE_this_epoch=np.average(MRE_each_batch)\n",
    "        train_NRMSE.append(NRMSE_this_epoch)\n",
    "        train_loss.append(loss_this_epoch)\n",
    "        train_MRE.append(MRE_this_epoch)\n",
    "\n",
    "        #上面是一个epoch的训练过程，下面是一个epoch的检测过程\n",
    "        with torch.no_grad():\n",
    "            test_MSE_each_batch=[]\n",
    "            test_loss_each_batch=[]\n",
    "            test_NRMSE_each_batch=[]\n",
    "            test_x=test_x.to(DEVICE)\n",
    "            test_y=test_y.to(DEVICE)\n",
    "            test_x_list = torch.split(test_x,batch_size,dim=0)\n",
    "            test_y_list = torch.split(test_y,batch_size,dim=0)\n",
    "            #测试也要按照minibatch去测量\n",
    "            for j in range(len(test_y_list)-1):\n",
    "                test_output=model(test_x_list[j])\n",
    "                test_loss_item=criterion(test_output,test_y_list[j])\n",
    "                test_loss_each_batch.append(test_loss_item.data.cpu())\n",
    "                test_MSE_each_batch.append(MRE(output,train_y).data.cpu())\n",
    "                test_NRMSE_each_batch.append(np.sqrt(test_loss_item.data.cpu())/(torch.max(test_y)-torch.min(test_y)).data.cpu())\n",
    "            test_NRMSE_this_epoch=np.average(test_NRMSE_each_batch)\n",
    "            test_loss_this_epoch=np.average(test_loss_each_batch)\n",
    "            test_MRE_this_epoch=np.average(test_MSE_each_batch)\n",
    "            test_NRMSE.append(test_NRMSE_this_epoch)\n",
    "            test_loss.append(test_loss_this_epoch)\n",
    "            test_MRE.append(test_MRE_this_epoch)\n",
    "\n",
    "\n",
    "        print('Epoch [{}/{}],  Train loss(MSE): {:.4f}, TEST loss(MSE): {:.4f},,time: {}'\n",
    "                        .format(i, EPOCH_NUM, loss_this_epoch,test_loss_this_epoch,timesince(start)))\n",
    "        \n",
    "        #early_stop\n",
    "        if i%3==0:\n",
    "            if test_loss_this_epoch>test_loss[max(0,i-5)]:\n",
    "                early_stop_p+=1\n",
    "        if early_stop_p>4:\n",
    "            break\n",
    "\n",
    "\n",
    "    return train_loss,test_loss,train_NRMSE,test_NRMSE,train_MRE,test_MRE\n",
    "\n",
    "\n",
    "train_loss,test_loss,train_NRMSE,test_NRMSE,train_MRE,test_MRE=train(TRAIN_X,TRAIN_Y,TEST_X,TEST_Y,BATCH_SIZE,EPOCH_NUM,CRITERION,OPTIMIZER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据进行单独点的测试，并进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练集和测试集的回归结果'''\n",
    "train_ref=TRAIN_Y[0:1000,0].data.cpu()\n",
    "train_x=TRAIN_X[0:1000].to(DEVICE)\n",
    "test_ref=TEST_Y[0:1000,0].data.cpu()\n",
    "test_x=TEST_X[0:1000].to(DEVICE)\n",
    "\n",
    "def regression_curve(x,ref,model,title):\n",
    "    x_list=torch.split(x,BATCH_SIZE,dim=0)\n",
    "    pred_list=[]\n",
    "    for i in range(len(x_list)-1):\n",
    "        pred_list.append(model(x_list[i]))\n",
    "    pred=torch.cat(pred_list,dim=0)\n",
    "    pred=pred.data.cpu()\n",
    "    # print(pred.shape,ref.shape)\n",
    "    # for i in range(100):\n",
    "    #     print('第{}个数据的输入第一通道均值为{},第二通道均值为{},预测值是{},label真值为{}'.format(i,torch.mean(x[i]),torch.mean(x[i]-x[max(i-1,0)]),pred[i],ref[i]))\n",
    "    plt.plot(pred[101:202],label='predicted moment')\n",
    "    plt.plot(ref[101:202],label='reference moment')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('knee moment')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def coefficient_deter(x,ref,model):\n",
    "    x_list=torch.split(x,BATCH_SIZE,dim=0)\n",
    "    pred_list=[]\n",
    "    for i in range(len(x_list)-1):\n",
    "        pred_list.append(model(x_list[i]))\n",
    "    pred=torch.cat(pred_list,dim=0)\n",
    "    pred=pred.data.cpu()\n",
    "    pred1=pred[101:202].float()\n",
    "    pred1=torch.squeeze(pred1,1)\n",
    "    y1=ref[101:202].float()\n",
    "    error=(pred1-y1)*(pred1-y1)\n",
    "    aver=torch.sum(y1)/101\n",
    "    dis=(y1-aver)*(y1-aver)\n",
    "    R2=1-torch.sum(error)/torch.sum(dis)\n",
    "    return R2\n",
    "\n",
    "\n",
    "regression_curve(train_x,train_ref,model,'training set')\n",
    "regression_curve(test_x,test_ref,model,'test set')\n",
    "print('coefficient of determination: example from training set {} ; example from test set{}'.format(coefficient_deter(train_x,train_ref,model),coefficient_deter(test_x,test_ref,model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_loss,label='test loss')\n",
    "plt.plot(train_loss,label='train loss')\n",
    "plt.xlabel('epoch_num')\n",
    "plt.ylabel('MSE(absolute value)')\n",
    "plt.title('MSE_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(test_NRMSE,label='test_nrmse')\n",
    "# plt.plot(train_NRMSE,label='train_nrmse')\n",
    "# plt.xlabel('epoch_num')\n",
    "# plt.ylabel('Noramlized root mean square error')\n",
    "# plt.title('per cent')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "print('最后模型的NRMSE在训练集上是{},测试集上是{}'.format(train_NRMSE[-1],test_NRMSE[-1]))\n",
    "print('最后模型的MRE在训练集上是{},测试集上是{}'.format(train_MRE[-1],test_MRE[-1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4db59b7d75187098e315d254b15c141341555b825ecc6cc2bfff10e5cb68aad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
