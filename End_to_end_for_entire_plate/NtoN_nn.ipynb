{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "# 数据预处理相关函数\n",
    "from Reader import Footscan_reader\n",
    "from Reader import gait_data_reader\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
    "LEARING_RATE=0.001\n",
    "BATCH_SIZE=128\n",
    "DEVICE=torch.device('cuda')\n",
    "\n",
    "footscan_reader = Footscan_reader()\n",
    "gaitdata_reader=gait_data_reader()\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.read the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load all data from data buffer file\n",
      "\n",
      " ************************************************** \n",
      "\n",
      "该部分数据中共有 20 位患者，平均每位患者有3.45次回访，共计69次,平均每次回访测试了6.565217391304348趟，共计453趟\n",
      "\n",
      " \n",
      "\n",
      "the size of planar pressure and moment data is seperately (100, 60, 63) and torch.Size([100, 18]) \n",
      "\n",
      "-24    78\n",
      "-48    75\n",
      "-36    74\n",
      "-12    69\n",
      " 36    48\n",
      " 24    42\n",
      " 48    34\n",
      " 12    33\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "info_dic=pickle.load(open('info_dic.pkl','rb'))\n",
    "output_info=pickle.load(open('../../processed_data/final_output.pkl','rb'))\n",
    "input_array=np.load('../../processed_data/final_input.npy')\n",
    "# input_array=np.expand_dims(input_array,2)\n",
    "\n",
    "print('load all data from data buffer file')\n",
    "print('\\n','*'*50,'\\n')\n",
    "\n",
    "valid_input=[]\n",
    "valid_norm_moment=[]\n",
    "valid_delta=[]\n",
    "valid_task=[]\n",
    "for i in range(input_array.shape[0]):\n",
    "    valid_input.append(input_array[i,:,:,:])\n",
    "    valid_norm_moment.append(output_info[i].norm_data)\n",
    "    valid_delta.append(output_info[i].delta)\n",
    "    valid_task.append(output_info[i].group)\n",
    "\n",
    "# remove a bad data with 80k loss\n",
    "index_great_loss=397\n",
    "if len(output_info)==453:\n",
    "    del valid_input[index_great_loss]\n",
    "    del valid_delta[index_great_loss]\n",
    "    del valid_norm_moment[index_great_loss]\n",
    "\n",
    "#output the test statistical information\n",
    "visit_list=gaitdata_reader.get_visit_list(output_info,info_dic)\n",
    "print('the size of planar pressure and moment data is seperately {} and {} \\n'.format(valid_input[0].shape,valid_norm_moment[0].shape))\n",
    "print(pd.value_counts(valid_task))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.data processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data of this trainning all from the task(week) of [-12, -24, -36, -48]\n",
      "the trainning video numbe is 1480 after DATA ARGUMENTATION\n",
      "input size after data argumentation is torch.Size([100, 70, 70])\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "#choose the task set and data argumentation \n",
    "task_set=[-12,-24,-36,-48]\n",
    "this_input=[]\n",
    "this_moment=[]\n",
    "this_gaitdata=[]\n",
    "this_delta=[]\n",
    "\n",
    "\n",
    "print('The data of this trainning all from the task(week) of',task_set)\n",
    "for i in range(len(valid_delta)):\n",
    "    if valid_task[i] in task_set:\n",
    "        e=footscan_reader.video_augment_padding(valid_input[i],70,70)\n",
    "        this_input.extend(e)\n",
    "        this_moment.extend([valid_norm_moment[i]]*5)\n",
    "        this_delta.extend([valid_delta[i]]*5)\n",
    "print('the trainning video numbe is {} after DATA ARGUMENTATION'.format(len(this_delta)))\n",
    "print('input size after data argumentation is',this_input[0].shape)\n",
    "print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one moment as our label\n",
    "predict_category_index=3\n",
    "print('we choose \"{}” as our prediction label during this training'.format(this_gaitdata[1].category[predict_category_index]))\n",
    "label_list=[]\n",
    "for i in range(len(this_moment)):\n",
    "    moment=this_moment[i]\n",
    "    for j in range(moment.shape[0]):\n",
    "        #3*i+1 means the y-axis\n",
    "        label_list.append(moment[j,predict_category_index*3+1])\n",
    "\n",
    "LABEL=torch.stack(label_list)\n",
    "LABEL=torch.unsqueeze(LABEL,1)\n",
    "label_ampli_factor=100\n",
    "LABEL=LABEL*label_ampli_factor\n",
    "print('we amplify the label {} times to get a mean value of {}'.format(label_ampli_factor,torch.mean(LABEL)))\n",
    "print('the final label shape is',LABEL.shape)\n",
    "print('*'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get input from video——5 channels per frame\n",
    "dif_amplify_factor=10\n",
    "pressure_amlify_factor=10\n",
    "input_list=[]\n",
    "for i in range(len(this_input)):\n",
    "    pressure_video=this_input[i]\n",
    "    (t,h,w)=pressure_video.shape\n",
    "    for j in range(t):\n",
    "        this_pressure=pressure_video[j,:,:]\n",
    "        if j==t-1:\n",
    "            next_pressure=torch.zeros((h,w))\n",
    "        else:\n",
    "            next_pressure=pressure_video[j+1,:,:]\n",
    "        \n",
    "        if j==0:\n",
    "            last_pressure=torch.zeros((h,w))\n",
    "        else:\n",
    "            last_pressure=pressure_video[j-1,:,:]\n",
    "        #考虑进入时间因素（用delta来表示）\n",
    "        dif_former=(this_pressure-last_pressure)/this_delta[i]*dif_amplify_factor\n",
    "        dif_latter=(next_pressure-this_pressure)/this_delta[i]*dif_amplify_factor\n",
    "        input_list.append(torch.stack([this_pressure,last_pressure,next_pressure,dif_former,dif_latter]))\n",
    "DATA=torch.stack(input_list)\n",
    "DATA=DATA*pressure_amlify_factor\n",
    "print('DATA shape is',DATA.shape)\n",
    "print('the mean abs value of the 5 channels of all data is: ',torch.mean(abs(DATA[0:5000,:,:,:]),dim=[0,2,3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_list=gaitdata_reader.get_visit_list(this_gaitdata[0:50],info_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the validation dataset--leave one subject out validation set\n",
    "validation_index=[]\n",
    "train_index=[]\n",
    "leave_subject_name=this_visit[1][0]\n",
    "for i in range(len(this_gaitdata)):\n",
    "    if info_dic[this_gaitdata[i].name]==leave_subject_name:\n",
    "        validation_index.extend(range(100*i,100*(i+1)))\n",
    "    else:\n",
    "        train_index.extend(range(100*i,100*(i+1)))\n",
    "print('Use the leave-one-subject-out strategy to get the validation dataset.....')\n",
    "print('the validation dataset is all data from {} consisting of {} pressure image input'.format(leave_subject_name,len(validation_index)))\n",
    "print('the training set is from other participants consisting of {} pressure image input'.format(len(train_index)))\n",
    "\n",
    "# for i in range(440):\n",
    "#     if i%10==0:\n",
    "#         validation_index.extend(range(100*i,100*(i+1)))\n",
    "#     else:\n",
    "#         train_index.extend(range(100*i,100*(i+1)))\n",
    "# print('just use the validation evenly sampled to give a fake fitting example')\n",
    "\n",
    "\n",
    "Final_dataset=[]\n",
    "for i in range(LABEL.shape[0]):\n",
    "    Final_dataset.append([DATA[i,:,:,:],LABEL[i,:]])\n",
    "validation_sampler=SubsetRandomSampler(validation_index)\n",
    "train_sampler=SubsetRandomSampler(train_index)\n",
    "validation_loader=DataLoader(Final_dataset,BATCH_SIZE,sampler=validation_sampler,drop_last=True)\n",
    "train_loader=DataLoader(Final_dataset,BATCH_SIZE,sampler=train_sampler,drop_last=True)\n",
    "# num=0\n",
    "# for x,y in test_loader:\n",
    "#     print(x.shape,y.shape)\n",
    "#     num+=1\n",
    "# print(num)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the moment-predicting netural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#回归模型构建\n",
    "'''\n",
    "2023/4/22\n",
    "处理足压片段来预测步态周期的力矩曲线\n",
    "\n",
    "模型概况：\n",
    "    金字塔conv\n",
    "    flatten\n",
    "    linear*1\n",
    "\n",
    "输入输出：\n",
    "    输入：该时刻的足压图像+该帧的变化量(batch,channel=5,height=180,width=63)\n",
    "    输出：该时刻的膝关节力矩(batch)\n",
    "'''\n",
    "\n",
    "INPUT_FEATURES=5\n",
    "HIDDEN_FEATURES_LIST=[16,32]\n",
    "KERNEL_SIZE_LIST=[(6,6),(5,5),(7,7),(3,3)]\n",
    "EPOCH_NUM=200\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,batch_size,input_features,hidden_features_list,kernel_size_list):\n",
    "        super(Net,self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.input_features = input_features\n",
    "        self.hidden_features_list=hidden_features_list\n",
    "        self.kernel_size_list=kernel_size_list\n",
    "\n",
    "        self.BN1=nn.BatchNorm2d(input_features).to(DEVICE)\n",
    "        self.pymarid_conv_1=nn.Conv2d(input_features,hidden_features_list[0],kernel_size_list[0],padding='same').to(DEVICE)                              \n",
    "        self.pymarid_conv_2=nn.Conv2d(input_features,hidden_features_list[0],kernel_size_list[1],padding='same').to(DEVICE)\n",
    "        self.pymarid_conv_3=nn.Conv2d(input_features,hidden_features_list[0],kernel_size_list[2],padding='same').to(DEVICE)\n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(hidden_features_list[0]*3),\n",
    "            nn.Conv2d(hidden_features_list[0]*3,hidden_features_list[1],kernel_size_list[3],padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.Linear=nn.Sequential(\n",
    "            nn.Linear(hidden_features_list[1]*45*17,1600),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1600,512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512,1),\n",
    "        ).to(DEVICE)\n",
    "\n",
    "    def forward(self,x):\n",
    "        if x.ndim!=4:\n",
    "            raise ValueError('输入数据ndim不为4')\n",
    "        else:\n",
    "            batch,features,height,width= x.shape\n",
    "            if batch!=self.batch_size or features != self.input_features:\n",
    "                raise ValueError('输入数据batch size 或者 input features 与model不符')\n",
    "            else:\n",
    "                pyramid_conv_output_list=[self.pymarid_conv_1(x),self.pymarid_conv_2(x),self.pymarid_conv_3(x)]\n",
    "                pyramid_conv_output=torch.cat(pyramid_conv_output_list,dim=1)\n",
    "                conv2_output=self.conv2(pyramid_conv_output)\n",
    "                y=self.Linear(conv2_output.reshape(batch,-1))\n",
    "                return y\n",
    "\n",
    "model = Net(BATCH_SIZE,INPUT_FEATURES,HIDDEN_FEATURES_LIST,KERNEL_SIZE_LIST).to(DEVICE)     \n",
    "print(model)\n",
    "a = torch.ones((BATCH_SIZE,INPUT_FEATURES,180,70)).to(DEVICE)\n",
    "b = model(a)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN TRAINNING\n",
    "start = time.time()\n",
    "def timesince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "#input shape:torch.size(batchsize,1)\n",
    "def MRE(pred,train_y):\n",
    "    relative_error=abs(pred-train_y)/train_y\n",
    "    return torch.mean(relative_error)\n",
    "\n",
    "\n",
    "def train(train_loader,test_loader,epoch_num,criterion,optimizer):\n",
    "    train_loss=[]\n",
    "    test_loss=[]\n",
    "    train_NRMSE=[]\n",
    "    test_NRMSE=[]\n",
    "    train_MRE=[]\n",
    "    test_MRE=[]\n",
    "    early_stop_p = 0\n",
    "    for i in range(epoch_num):\n",
    "        #trainning process\n",
    "        loss_each_batch=[]\n",
    "        MRE_each_batch=[]\n",
    "        NRMSE_each_batch=[]\n",
    "        for x,y in train_loader:\n",
    "            train_x=x.to(DEVICE)\n",
    "            train_y=y.to(DEVICE)\n",
    "            output=model(train_x).to(DEVICE)\n",
    "            output=output.float()\n",
    "            train_y=train_y.float()\n",
    "            loss = criterion(output,train_y)\n",
    "            if loss>10000:\n",
    "                print(loss)\n",
    "                print(j)\n",
    "                print(output)\n",
    "                print(train_y)\n",
    "            optimizer.zero_grad()   \n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "\n",
    "            loss_each_batch.append(loss.data.cpu())\n",
    "            MRE_each_batch.append(MRE(output,train_y).data.cpu())\n",
    "            NRMSE_each_batch.append(np.sqrt(loss.data.cpu())/(torch.max(train_y)-torch.min(train_y)).data.cpu())\n",
    "\n",
    "        train_NRMSE.append(np.average(NRMSE_each_batch))\n",
    "        train_loss.append(np.average(loss_each_batch))\n",
    "        train_MRE.append(np.average(MRE_each_batch))\n",
    "\n",
    "        #validation process\n",
    "        with torch.no_grad():\n",
    "            test_MRE_each_batch=[]\n",
    "            test_loss_each_batch=[]\n",
    "            test_NRMSE_each_batch=[]\n",
    "            for test_x,test_y in test_loader:\n",
    "                test_x=test_x.to(DEVICE)\n",
    "                test_y=test_y.to(DEVICE)\n",
    "                test_output=model(test_x)\n",
    "                test_loss_item=criterion(test_output,test_y)\n",
    "                test_loss_each_batch.append(test_loss_item.data.cpu())\n",
    "                test_MRE_each_batch.append(MRE(output,train_y).data.cpu())\n",
    "                test_NRMSE_each_batch.append(np.sqrt(test_loss_item.data.cpu())/(torch.max(test_y)-torch.min(test_y)).data.cpu())\n",
    "            \n",
    "            test_NRMSE.append(np.average(test_NRMSE_each_batch))\n",
    "            test_loss.append(np.average(test_loss_each_batch))\n",
    "            test_MRE.append(np.average(test_MRE_each_batch))\n",
    "\n",
    "\n",
    "        print('Epoch [{}/{}],  Train loss(MSE): {:.4f}, TEST loss(MSE): {:.4f},time: {}'\n",
    "                        .format(i, EPOCH_NUM, train_loss[-1],test_loss[-1],timesince(start)))\n",
    "        \n",
    "        #early_stop\n",
    "        if i%3==0 and i>2:\n",
    "            if test_loss[-1]>min(test_loss[max(0,i-5):i]):\n",
    "                early_stop_p+=1\n",
    "        if early_stop_p>4:\n",
    "            break\n",
    "\n",
    "    return train_loss,test_loss,train_NRMSE,test_NRMSE,train_MRE,test_MRE\n",
    "\n",
    "CRITERION = nn.MSELoss(reduction='mean')\n",
    "OPTIMIZER = torch.optim.Adam(model.parameters(), lr=LEARING_RATE)\n",
    "train_loss,test_loss,train_NRMSE,test_NRMSE,train_MRE,test_MRE=train(train_loader,validation_loader,EPOCH_NUM,CRITERION,OPTIMIZER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据进行单独点的测试，并进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plot the predicting curve'''\n",
    "def coefficient_deter(pred1,y1):\n",
    "    error=(pred1-y1)*(pred1-y1)\n",
    "    aver=np.average(y1)\n",
    "    dis=(y1-aver)*(y1-aver)\n",
    "    R2=1-np.sum(error)/np.sum(dis)\n",
    "    return R2\n",
    "\n",
    "DEVICE='cpu'\n",
    "test_gait_loader=DataLoader(Final_dataset,BATCH_SIZE,sampler=validation_index)\n",
    "train_gait_loader=DataLoader(Final_dataset,BATCH_SIZE,sampler=train_index)\n",
    "model=model.cpu()\n",
    "x_list=[]\n",
    "ref_list=[]\n",
    "pred_list=[]\n",
    "coe_list=[]\n",
    "iter_num=0\n",
    "for x,y in test_gait_loader:\n",
    "    pred_list.append(model(x).data.cpu().numpy())\n",
    "    x_list.append(x.numpy())\n",
    "    ref_list.append(y.numpy())\n",
    "    coe_list.append(coefficient_deter(pred_list[-1],ref_list[-1]))\n",
    "    iter_num+=1\n",
    "    if iter_num>1:\n",
    "        break\n",
    "print(type(pred_list[0]))\n",
    "plt.plot(pred_list[0][0:100,0],label='predicted moment')\n",
    "plt.plot(ref_list[0][0:100],label='reference moment')\n",
    "plt.xlabel('per centage of a gait')\n",
    "plt.ylabel('knee moment')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('mean value of coefficient of determination of validation dataset is {}'.format(sum(coe_list)/len(coe_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_loss,label='test loss')\n",
    "plt.plot(train_loss,label='train loss')\n",
    "plt.xlabel('epoch_num')\n",
    "plt.ylabel('MSE(absolute value)')\n",
    "plt.title('MSE_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(test_NRMSE,label='test_nrmse')\n",
    "# plt.plot(train_NRMSE,label='train_nrmse')\n",
    "# plt.xlabel('epoch_num')\n",
    "# plt.ylabel('Noramlized root mean square error')\n",
    "# plt.title('per cent')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "print('最后模型的NRMSE在训练集上是{},测试集上是{}'.format(train_NRMSE[-1],test_NRMSE[-1]))\n",
    "print('最后模型的MRE在训练集上是{},测试集上是{}'.format(train_MRE[-1],test_MRE[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_MRE,label='test MRE')\n",
    "plt.plot(train_MRE,label='train MRE')\n",
    "plt.legend()\n",
    "plt.ylim(-1,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unusing code stroage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时train 的 TRAIN_X和TRAIN_Y再做一次shuffle，因为之前是以一次测试的一百帧为单位进行打乱，所以处于一种宏观无序，但是微观有序的状态,这次打乱之后就微观无序了；\n",
    "TRAIN_X_tensor_list=[]\n",
    "TRAIN_Y_tensor_list=[]\n",
    "origin_tensor_list=[]\n",
    "for i in range(TRAIN_X_RAW.shape[0]):\n",
    "    origin_tensor_list.append((TRAIN_X_RAW[i,:,:,:],TRAIN_Y_RAW[i,:]))\n",
    "random.shuffle(origin_tensor_list)\n",
    "for j in range(len(origin_tensor_list)):\n",
    "    TRAIN_X_tensor_list.append(origin_tensor_list[j][0])\n",
    "    TRAIN_Y_tensor_list.append(origin_tensor_list[j][1])\n",
    "TRAIN_X=torch.stack(TRAIN_X_tensor_list)\n",
    "TRAIN_Y=torch.stack(TRAIN_Y_tensor_list)\n",
    "print(TRAIN_X.shape,TRAIN_Y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "data shuffel\n",
    "origin_list=[]\n",
    "for i in range(len(this_input)):\n",
    "    origin_list.append((this_input[i],this_moment[i],this_delta[i],this_gaitdata[i]))\n",
    "random.shuffle(origin_list)\n",
    "for i in range(len(origin_list)):\n",
    "    this_input[i]=origin_list[i][0]\n",
    "    this_moment[i]=origin_list[i][1]\n",
    "    this_delta[i]=origin_list[i][2]\n",
    "    this_gaitdata[i]=origin_list[i][3]\n",
    "print('Finish the DATA SHUFFEL')\n",
    "print('*'*50)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4db59b7d75187098e315d254b15c141341555b825ecc6cc2bfff10e5cb68aad4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
